# 线程进程&&多进程多线程&&并发并行

## #1 进程

>  狭义理解就是操作系统中一段程序的执行过程。那么广义上，进程是指一个具有一定独立功能的程序操作系统中关于某个数据集合进行的一次运行活动。是操作系统程序动态执行的基本单元。在传统的操作系统中，进程既是一个操作系统的基本分配单元，也是操作系统的基本执行单元。

cpu的运行模式是不断的从pc寄存器取指执行，但是用户程序指令中会有io指令，也会有计算指令，而io指令耗时比计算指令高很多，如果在执行io时，cpu一直等待io完成后再执行下一条，这样必然造成cpu的使用**效率**低下。
为了解决这个问题，结合生活中烧水的例子："在把水壶放到炉子上之后，我们不需要一直等着水壶，我们可以去做别的事情，等到水壶烧开了，发出提醒的声音之后再切换回来使用热水。"
类比到计算机中，如果程序出现io阻塞了，可以切换到另一道程序继续执行，在一个CPU上交替的执行多个程序(并发)，这样能够提高cpu的使用效率。
为了能够将运行的程序切换到另一个程序运行，直观来看只需要修改PC寄存器就可以了，但是实际上还有很多上下文信息需要切换，比如各个寄存器的信息。因此为了区分运行中的程序和静态程序，引入了进程的概念即**运行中的程序，**进程由资源和执行序列两部分组成。每个进程都有一个存放运行时信息的结构: PCB（process control block），会存放切换时需要保留的上下文信息。

## #2 线程

>  线程是进程中执行运算的最小单元，是操作系统执行处理机制的基本单位。每个进程至少有一个线程，线程可以利用进程所拥有的资源执行调度和运算。

操作系统中为了将资源和指令执行序列区分开，引入了**线程**的概念，线程作为操作系统中的最小的调度单位。线程的模型是多个执行序列 + 一个地址空间。因此线程的切换不需要切换进程的内存映射表，这样保留了并发的特点，避免了进程切换的代价。

**进程与线程的对比**

- 进程是操作系统资源分配的基本单位，所有与该进程有关的资源，均会被记录在进程控制块PCB中，以表示该进程所拥有的资源。同一进程下的所有线程共享该进程下的所有资源。
- 线程是分配处理机的基本单位，与系统资源分配无关。事实上，正在在处理机上运行的是线程，并非进程。
- 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。
- 线程在执行的时候需要协作同步，不同进程的线程间要利用消息通信方法实现同步。

**进程与线程的关系**

- 进程将CPU资源分给线程，即真正在CPU上运行的是线程。
- 操作资源分配给进程，同一进程的所有线程共享该进程的所有资源。

**进程与线程的区别**

- 同一个进程中的线程共享同一内存空间，但是进程之间是独立的。
- 同一个进程中的所有线程的数据是共享的（进程通讯），进程之间的数据是独立的。
- 对主线程的修改可能会影响其他线程的行为，但是父进程的修改（除了删除以外）不会影响其他子进程。
- 线程是一个上下文的执行指令，而进程则是与运算相关的一簇资源。
- 同一个进程的线程之间可以直接通信，但是进程之间的交流需要借助中间代理来实现。
- 创建新的线程很容易，但是创建新的进程需要对父进程做一次复制。
- 一个线程可以操作同一进程的其他线程，但是进程只能操作其子进程。
- 线程启动速度快，进程启动速度慢（但是两者运行速度没有可比性）。
- 进程切换时需要资源切换，而线程切换只需要切换PC指针。

## #3 多进程

>  在同一个时间里，同一个计算机系统中如果允许两个或两个以上的进程处于运行状态，这便是多任务（多进程）。现代的操作系统几乎都是多进程操作系统，能够同时管理多个进程的运行。 多进程带来的好处是明显的。但是多进程对于系统的资源要求甚高，资源浪费也比较严重。应用多进程场景最多的是windows系统，例如同时打开运行软件，每个软件打开相当于运行一个进程。 

## #4 多线程

>  在一段完整的代码中，往往会有需要独立的代码模块，而这些独立运行的程序片段叫作“线程”（Thread），利用多个线程编程的概念就叫作多线程处理(多线程编程)，多线程是为了同步完成多项任务，不是为了提高运行效率，而是为了提高资源使用效率来提高系统的效率。多线程是在程序在同一时间需要完成多项任务的时候实现的。多线程的目的仅仅是为了提高资源利用效率。各个线程执行自己的任务，这些线程可以”同时进行“。同时进行并非同一时刻进行，而是在某一时间段内，完成所有任务，任务的运行有先后顺序。

## #5 并发

![z1n24ai2dk](C:\Users\psj\Desktop\markdown\z1n24ai2dk.png)

并发就是只有一个CPU资源，程序（或线程）之间要竞争得到执行机会。图中的第一个阶段，在A执行的过程中B，C不会执行，因为这段时间内这个CPU资源被A竞争到了，同理，第二个阶段只有B在执行，第三个阶段只有C在执行。其实，并发过程中，A，B，C并不是同时在进行的（微观角度）。但又是同时进行的（宏观角度）。

## #6 并行

![xk32m4f60l](C:\Users\psj\Desktop\markdown\xk32m4f60l.png)

>  并行指两个或两个以上事件（或线程）在同一时刻发生，是真正意义上的不同事件或线程在同一时刻，在不同CPU资源上（多核），同时执行。并行，不存在像并发那样竞争CPU资源，等待执行的概念，因为并行状态下的线程分布在不同的CPU上。

## #7 通过多线程实现并发，并行

- 在CPU比较繁忙，资源不足的时候（开启了很多进程），操作系统只为一个含有多线程的进程分配仅有的CPU资源，这些线程就会为自己尽量多抢时间片，这就是通过多线程实现并发，线程之间会竞争CPU资源争取执行机会。
- 在CPU资源比较充足的时候，一个进程内的多线程，可以被分配到不同的CPU资源，这就是通过多线程实现并行。
- 至于多线程实现的是并发还是并行？上面所说，所写多线程可能被分配到一个CPU内核中执行，也可能被分配到不同CPU执行，分配过程是操作系统所为，不可人为控制。所有，如果有人问我我所写的多线程是并发还是并行的？我会说，都有可能。
- 不管并发还是并行，都提高了程序对CPU资源的利用率，最大限度地利用CPU资源。

## #8 内核级线程的实现

![image-20211117211514684](C:\Users\psj\AppData\Roaming\Typora\typora-user-images\image-20211117211514684.png)

### 核心级线程与用户级线程有什么区别呢？

​		核心级线程需要在用户态和核心态里面跑，在用户态里跑需要一个用户栈，在核心态里面跑需要一个核心栈。用户栈和核心栈合起来称为一套栈，这就是核心级线程与用户级线程一个很重要的区别，从一个栈变成了一套栈。用户级线程用TCB切换栈的时候是在一个栈与另外一个栈之间切换，核心级线程就是在一套栈与另外一套栈之间的切换（核心级线程切换），核心级线程的TCB应该是在内核态里面。

### 用户栈与内核栈之间的关联:

​		内核栈什么时候出现？当线程进入内核的时候就应该建立一个属于这个线程的内核栈，那么线程是如何进入系统内核的？通过INT中断。当线程下一次进入内核的时候，操作系统可以根据一些硬件寄存器来知道这个哪个线程，它对应的内核栈在哪里。同时会将用户态的栈的位置（SS、SP）和程序执行到哪个地方了（CS、IP）都压入内核栈。等线程在内核里面执行完（也就是IRET指令）之后就根据进入时存入的SS、SP的值找到用户态中对应栈的位置，根据存入的CS、IP的值找到程序执行到哪个地方。

### 核心级线程的实现实例：

![image-20211117212433630](C:\Users\psj\AppData\Roaming\Typora\typora-user-images\image-20211117212433630.png)

​		**SS:存放栈的段地址；SP:堆栈寄存器SP(stack pointer)存放栈的偏移地址;** 		内核栈中的ss:sp指向用户栈

​		从中断入口和中断出口开始讲：					

​		执行到A()调用的时候会将A函数的返回地址也就是B()函数的起始地址压入当前线程的用户栈中，然后转入fork()这个系统调用，在fork()中肯定会通过INT0x80这个中断号进入操作系统内核；进入内核的时候会将用户栈的位置以及当前程序的执行地址都压入到内核栈中，然后开始执行fork()。根据前面讲的系统调用知识可以知道，INT0x80的中断服务程序是_system_call这个宏定义，对于不同的系统调用_system_call执行的语句不同，对于fork()来说，如下：

```c
_system_call:
	push %ds..%fs 
	push1 %edx...  //首先将一堆寄存器的值push到栈中，因为刚刚进入内核态的时候，这些寄存器的值都是用户态的内容，所以需要将这些值push到栈中为下一次这个线程的执行做准备。
	call sys_fork  //接着执行sys_fork,这个通过sys_call_table这张表找到的
	push1 %eax
```

首先将一堆寄存器的值push到栈中，因为刚刚进入内核态的时候，这些寄存器的值都是用户态的内容，所以需要将这些值push到栈中为下一次这个线程的执行做准备。接着执行sys_fork,这个通过sys_call_table这张表找到的，这部分知识可以参考系统调用部分的东西。



​		/*在sys_fork执行过程中可能需要切换到另外一个线程，它是如何切换的？其实也就是通过判断

```c
movl _current;%eax  //_current 指的是当前线程的TCB。
cmpl $0,state(%eax)
jne reschedule  //判断当前线程的状态是不是0，如果不是就调度，即执行jne reschedule。
cmp 1$0,counter(%eax)
je  reschedule  //判断当前线程的时间片是不是用完了，如果用完了也需要调度。
ret_from sys_call:
```

```c
reschedule:
  pushl $ret_from_sys_call
  jmp schedule
```

​		调度程序首先将返回地址 ret_from_sys_call 压栈，接着执行调度函数 _schedule。具体的调度算法忽略，主要看线程切换的过程。调度函数应该是下面这个样子，首先找到需要执行的下一个线程，然后转到该线程执行。

```c
void schedule(void)
{
	next=i;				// 找到需要执行的下一个线程
	switch_ to(next);	// 转到该线程执行
}
```

​		*/



执行完这个线程之后就会转到ret_from_sys_call执行

```c
ret_from_sys_call:
	popl %eax...
	pop %fs
	iret
```

首先将进入内核时存储的寄存器的值弹栈，也就是将当前状态的寄存器值恢复到执行系统调用前的本线程的状态。接着利用iret转到用户态，接着执行。

---

![image-20211117221001662](C:\Users\psj\AppData\Roaming\Typora\typora-user-images\image-20211117221001662.png)

将用户态各寄存器传给内核态，进行复制创建子进程。

![image-20211117221500802](C:\Users\psj\AppData\Roaming\Typora\typora-user-images\image-20211117221500802.png)







![image-20211117221842232](C:\Users\psj\AppData\Roaming\Typora\typora-user-images\image-20211117221842232.png)

**这里  子进程的eax置为0  所以fork（）子进程的返回值位0**

---

切换五步：

+ 从用户栈找到内核栈
+ 内核栈找到tcp
+ tcb经过switch_to完成tcb的切换
+ tcb找到内核栈
+ 内核栈找到用户栈

![image-20211117222929791](C:\Users\psj\AppData\Roaming\Typora\typora-user-images\image-20211117222929791.png)

---

# 操作系统CPU调度策略

### 调度指标：

+ 周转时间：从任务进入到任务结束的时间
+ 响应时间：操作发生到响应
+ 吞吐量：完成的任务量

### 常见调度算法：

+ 先来先服务
+ 短作业优先：会产生饥饿，响应时间短
+ 时间片轮转
+ 优先级调度

## 响应时间和周转时间同时存在呢？

​		直观想法：定义前台任务和后台任务两个队列，因为前台任务更看重响应时间，所以使用RR，后台任务更看重周转时间，采用SJF，只有当前台任务没有的时候才调度后台任务，

​		但是这样会有很多问题？比如前台任务一直存在，那么后台任务是不是永远不执行了？执行一个后台任务的时间一般比较长，那么是不是这段时间就不响应前台任务？

​		对于第一个问题，给任务设置优先级，前台任务的优先级大于后台任务优先级，首先执行优先级高的任务，随着时间的增长，后台任务优先级动态升高，这样后台任务才有执行的机会。
​		对于第二个问题，采用时间片的方式，后台任务执行一段时间之后就跳到下一个任务。

除此之外还有很多其他的问题？例如：

​		我们怎么知道哪些是前台任务，哪些是后台任务，fork时告诉我们吗?
​		gcc就一点不需要交互吗? Ctrl+C按键怎么工作?
​		word就不会执行一段批处理吗? Ctrl+F按键?
​		SJF中的短作业优先如何体现? 如何判断作业的长度?

### 一个schdule()实例

在不同的领域，调度算法各不相同。我们讨论的是在一个普通的PC机上的调度。

看一下[Linux](https://so.csdn.net/so/search?from=pc_blog_highlight&q=Linux)0.11的schedule()函数，进程调度的核心就是找到next，并且switch_to(next);

```c
//在kernel/sched.c中
void Schedule(void) 
{ 
	while(1) 
	{ 
		c=-1; next=0; i=NR_TASKS;
		p=&task[NR_TASKS];
		while(--i)
		{
			if((*p->state == TASK_RUNNING && (*p)->counter>c)
			c=(*p)->counter, next=i;   // 求counter最大的进程
		}
		if(c) 
			break; 		//找到了最大的counter
		for(p=&LAST_TASK;p>&FIRST_TASK;--p)
			(*p)->counter=((*p)->counter>>1)+(*p)->priority; // 这个for循环是设置所有进程的counter，这个for循环执行的条件是，当就绪队列中所有的进程的counter小于等于0才执行。
	}
	switch_to(next);
}
```

在Linux中，将PCB做成了一个数组，NR_TASKS就是数组的范围。
在schedule中，首先将p指向PCB的最后一个元素，然后遍历整个数组。如果该进程的state为TASK_RUNNING，TASK_RUNNING表示就绪状态，并且该进程的counter>c，就将该进程的counter赋给c，该进程设置为next。

### counter的两个作用

##### 时间片

##### 优先级

```c
for(p=&LAST_TASK;p>&FIRST_TASK;--p)
	(*p)->counter=((*p)->counter>>1)+(*p)->priority; 
```

​		这个for是设置所有进程的counter，如果当前进程的counter为0，那么一次循环之后，当前进程的counter就为priority；但是如果当前进程不为0呢？换言之就是该进程不处于就绪队列呢，那么经过一次循环之后该进程的counter肯定大于处于就绪队列的进程（当priority相同时）；也就是说阻塞的进程再就绪以后优先级高于非阻塞进程；同时进程阻塞的时间越长，该进程的counter越大，为什么？

​		第一次执行这个for循环时，如果某进程为阻塞状态，那么其counter为priority
​		第二次执行这个for循环时，如果该进程为阻塞状态，那么其counter为priority+priority/2

​		如果该进程一直阻塞，那么其counter为 p+p/2+p/4+p/8，这样counter一直增加，当该进程一旦处于就绪
​		状态，它的counter就会变得很大。进程为什么会阻塞，很大可能就是进程IO操作，IO操作不正是前台进程的特征吗？也就是说会优先执行前台进程。
